{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here the particles are made to converge so as to find a sequence\n",
    "which is able to achieve the target score\n",
    "\"\"\"\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import json\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 50\n",
    "MAX_INPUTS = 10\n",
    "MAX_PARTICLES = 10\n",
    "V_MAX = 10 #Maximum velocity change allowed\n",
    "MAX_EPOCHS = 200\n",
    "START_RANGE_MIN = 140\n",
    "START_RANGE_MAX = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, pBest):\n",
    "        self.data = [0] *  MAX_INPUTS\n",
    "        self.pBest = pBest\n",
    "        self.velocity = 0.0\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "    \n",
    "    def set_data(self, value):\n",
    "        self.data = value\n",
    "    \n",
    "    def set_pBest(self, value):\n",
    "        self.pBest = value\n",
    "        \n",
    "    def get_pBest(self):\n",
    "        return self.pBest\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        return self.velocity\n",
    "    \n",
    "    def set_velocity(self, value):\n",
    "        self.velocity = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_Particles():\n",
    "    particles = []\n",
    "    for i in range(MAX_PARTICLES):\n",
    "        newParticle = Particle(0)\n",
    "        total = 0\n",
    "        data = []\n",
    "        for j in range(MAX_INPUTS):\n",
    "            data.append(np.floor(np.random.uniform(START_RANGE_MIN, START_RANGE_MAX)))\n",
    "        \n",
    "        newParticle.set_data(data)\n",
    "        newParticle.set_pBest(np.sum(data))\n",
    "        particles.append(copy.deepcopy(newParticle))\n",
    "    \n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_problem(index, particles):\n",
    "    val = 0\n",
    "    a = particles[index].get_data()\n",
    "    for i in a:\n",
    "        val += i\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_fitness(particles):\n",
    "    minimum = 0\n",
    "    for i in range(MAX_PARTICLES):\n",
    "        #print(\"i: \" + str(i))\n",
    "        if i!=minimum: \n",
    "            if np.abs(TARGET - test_problem(i, particles))<np.abs(TARGET - test_problem(minimum, particles)):\n",
    "                minimum = i\n",
    "    \n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_velocity(gBestIndex, particles):\n",
    "    \n",
    "    bestVal = test_problem(gBestIndex, particles)\n",
    "    for i in range(MAX_PARTICLES):\n",
    "        testVal = test_problem(i, particles)\n",
    "        velocity = particles[i].get_velocity() + (2 * np.random.uniform() * (bestVal - testVal))\n",
    "        velocity += (2 * np.random.uniform() * (particles[i].get_pBest() - testVal))\n",
    "        \n",
    "        if velocity > V_MAX:\n",
    "            velocity = V_MAX\n",
    "        elif velocity < -V_MAX:\n",
    "            velocity = -V_MAX\n",
    "        \n",
    "        particles[i].set_velocity(velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_particles(particles, gBest):\n",
    "    for i in range(MAX_PARTICLES):\n",
    "        data = particles[i].get_data()\n",
    "        temp = particles[gBest].get_data()\n",
    "        vel = particles[i].get_velocity()\n",
    "        for y in range(len(data)):\n",
    "            if data[y] != temp[y]:\n",
    "                data[y] += vel\n",
    "                data[y]=np.floor(data[y])\n",
    "        particles[i].set_data(data)\n",
    "        \n",
    "        total = test_problem(i, particles)\n",
    "        if np.abs(TARGET - total) < particles[i].get_pBest():\n",
    "            particles[i].set_pBest(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PSO_algo():\n",
    "    epoch = 1\n",
    "    result = []\n",
    "    solution = -1\n",
    "    \n",
    "    particles = initialize_Particles()\n",
    "    random.seed(10)\n",
    "    \n",
    "    while epoch<MAX_EPOCHS:\n",
    "\n",
    "        gBest = max_fitness(particles)\n",
    "        \n",
    "        save_data = {}\n",
    "        save_data['epoch'] = epoch\n",
    "        save_data['gBest'] = gBest\n",
    "        with open('save.json', 'w') as fp:\n",
    "            json.dump(save_data, fp, sort_keys=True, indent=4)\n",
    "\n",
    "        for i in range(MAX_PARTICLES):\n",
    "            if test_problem(i, particles)==TARGET:\n",
    "                result = particles[i].get_data()\n",
    "                solution = i\n",
    "                break\n",
    "        \n",
    "        if solution>=0:\n",
    "            print(result)\n",
    "            break\n",
    "                \n",
    "        calc_velocity(gBest, particles)\n",
    "        update_particles(particles, gBest)\n",
    "        \n",
    "        #print(\"Best in epoch \" + str(epoch) +\": \" + str(particles[gBest].get_data()))\n",
    "        print(str(np.sum(particles[gBest].get_data())))\n",
    "        with open('data.pk1', 'w') as fp:\n",
    "            pickle.dump(particles, fp, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        epoch += 1\n",
    "    print(particles[gBest].get_data()[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1674.0\n",
      "1593.0\n",
      "1507.0\n",
      "1420.0\n",
      "1328.0\n",
      "1235.0\n",
      "1138.0\n",
      "1074.0\n",
      "999.0\n",
      "901.0\n",
      "823.0\n",
      "726.0\n",
      "637.0\n",
      "540.0\n",
      "448.0\n",
      "355.0\n",
      "288.0\n",
      "194.0\n",
      "129.0\n",
      "[16.0, 3.0, 1.0, -27.0, 17.0, 16.0, 25.0, -20.0, 5.0, 14.0]\n",
      "-27.0\n"
     ]
    }
   ],
   "source": [
    "#print(max_fitness())\n",
    "PSO_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([26.0, -26.0, 21.0, 9.0, 3.0, 22.0, -3.0, -32.0, -23.0, 18.0], 15.0)\n",
      "([1.0, 27.0, -13.0, 9.0, -15.0, 27.0, -17.0, -18.0, 36.0, 3.0], 40.0)\n",
      "([1.0, 27.0, 21.0, 9.0, -5.0, -3.0, -15.0, -11.0, 7.0, 18.0], 49.0)\n",
      "([-13.0, 22.0, -8.0, -3.0, -23.0, -4.0, -13.0, 50.0, 15.0, 3.0], 26.0)\n",
      "([4.0, -34.0, 21.0, 9.0, -29.0, 22.0, -11.0, 1.0, 17.0, -25.0], -25.0)\n",
      "([-11.0, 24.0, 21.0, -14.0, -5.0, 36.0, -15.0, -11.0, 7.0, 18.0], 50.0)\n",
      "([-52.0, 4.0, 21.0, -16.0, -5.0, 18.0, -12.0, -1.0, 7.0, -8.0], -44.0)\n",
      "([21.0, 9.0, 21.0, 3.0, 8.0, -14.0, -15.0, 16.0, 7.0, 25.0], 81.0)\n",
      "([-14.0, 21.0, -20.0, 17.0, -28.0, -3.0, 5.0, 63.0, 42.0, -17.0], 66.0)\n",
      "([15.0, -9.0, -2.0, -22.0, 27.0, -3.0, 18.0, 54.0, -21.0, 4.0], 61.0)\n"
     ]
    }
   ],
   "source": [
    "with open('data.pk1', 'rb') as input:\n",
    "    par1 = pickle.load(input)\n",
    "    for i in range(len(par1)):\n",
    "        print(par1[i].get_data(), np.sum(par1[i].get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "if(os.path.isfile('data.pk1')):\n",
    "    print(\"found\")\n",
    "    \n",
    "with open('save.json', 'r') as ip:\n",
    "    open_data = json.load(ip)\n",
    "\n",
    "print(open_data['gBest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
